{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rq1vdXFKlpg2"
      },
      "outputs": [],
      "source": [
        "# 1 Download the corpus and split it into training and testing sets to build a data frame.\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from nltk.parse.dependencygraph import DependencyGraph\n",
        "\n",
        "# Download the dependency treebank corpus\n",
        "url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\"\n",
        "filename = \"dependency_treebank.zip\"\n",
        "urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "# Extract the files\n",
        "with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "# Define the boundaries for dataset splitting\n",
        "train_size = 100\n",
        "val_size = 50\n",
        "\n",
        "# Create directories for saving the datasets\n",
        "os.makedirs(\"data/train\", exist_ok=True)\n",
        "os.makedirs(\"data/val\", exist_ok=True)\n",
        "os.makedirs(\"data/test\", exist_ok=True)\n",
        "\n",
        "# Iterate over each file and split it into the corresponding dataset based on the boundaries\n",
        "for i, file in enumerate(sorted(os.listdir(\"dependency_treebank\"))):\n",
        "    with open(os.path.join(\"dependency_treebank\", file), 'r') as f:\n",
        "        # Load each file using the DependencyGraph class\n",
        "        dg = DependencyGraph(f.read())\n",
        "        # Convert the dependency tree to a CoNLL-formatted string\n",
        "        conll_str = dg.to_conll(4)  # Use index 4 for word and index 6 for POS tag\n",
        "        # Remove the third column containing the numerical values\n",
        "        conll_str = '\\n'.join(['\\t'.join(line.split('\\t')[:2]) for line in conll_str.split('\\n')])\n",
        "        if i < train_size:\n",
        "            with open(os.path.join(\"data/train\", file), 'w') as f_train:\n",
        "                f_train.write(conll_str)\n",
        "        elif i < train_size + val_size:\n",
        "            with open(os.path.join(\"data/val\", file), 'w') as f_val:\n",
        "                f_val.write(conll_str)\n",
        "        else:\n",
        "            with open(os.path.join(\"data/test\", file), 'w') as f_test:\n",
        "                f_test.write(conll_str)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 Create a data frame\n",
        "import pandas as pd\n",
        "\n",
        "# Create empty lists to store the data\n",
        "train_data = []\n",
        "val_data = []\n",
        "test_data = []\n",
        "\n",
        "# Iterate over each file and split it into the corresponding dataset based on the boundaries\n",
        "for i, file in enumerate(sorted(os.listdir(\"dependency_treebank\"))):\n",
        "    with open(os.path.join(\"dependency_treebank\", file), 'r') as f:\n",
        "        # Load each file using the DependencyGraph class\n",
        "        dg = DependencyGraph(f.read())\n",
        "        # Convert the dependency tree to a CoNLL-formatted string\n",
        "        conll_str = dg.to_conll(4)  # Use index 4 for word and index 6 for POS tag\n",
        "        # Split CoNLL-formatted string into lines\n",
        "        conll_lines = conll_str.split('\\n')\n",
        "        # Extract words and POS tags and store them in the data lists\n",
        "        if i < train_size:\n",
        "            train_data.extend([line.split('\\t')[:2] for line in conll_lines if line])\n",
        "        elif i < train_size + val_size:\n",
        "            val_data.extend([line.split('\\t')[:2] for line in conll_lines if line])\n",
        "        else:\n",
        "            test_data.extend([line.split('\\t')[:2] for line in conll_lines if line])\n",
        "\n",
        "# Create dataframes from the lists\n",
        "train_df = pd.DataFrame(train_data, columns=['Word', 'POS'])\n",
        "val_df = pd.DataFrame(val_data, columns=['Word', 'POS'])\n",
        "test_df = pd.DataFrame(test_data, columns=['Word', 'POS'])\n",
        "\n",
        "print(train_df.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H6YbHpHlp8l",
        "outputId": "76b361ef-2b24-45f3-b8cb-8a65095b2c76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Word  POS\n",
            "0  Pierre  NNP\n",
            "1  Vinken  NNP\n",
            "2       ,    ,\n",
            "3      61   CD\n",
            "4   years  NNS\n",
            "5     old   JJ\n",
            "6       ,    ,\n",
            "7    will   MD\n",
            "8    join   VB\n",
            "9     the   DT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3 Count and plot the distribution of the number of words in each file in a dependency tree bank.\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_dir = \"dependency_treebank\"\n",
        "\n",
        "# create a list to store the number of tokens in each file\n",
        "num_tokens = []\n",
        "\n",
        "# iterate over each file in the corpus directory and count the number of tokens in each file\n",
        "for file in os.listdir(data_dir):\n",
        "    with open(os.path.join(data_dir, file), 'r') as f:\n",
        "        # count the number of non-empty lines in the file\n",
        "        count = sum([1 for line in f if line.strip()])\n",
        "        num_tokens.append(count)\n",
        "\n",
        "# plot a histogram of the number of tokens per file\n",
        "plt.hist(num_tokens, bins=20)\n",
        "plt.xlabel(\"Number of Tokens\")\n",
        "plt.ylabel(\"Number of Files\")\n",
        "plt.title(\"Histogram of Dataset Size\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "oUMAFSW3WYqD",
        "outputId": "80847e8a-c2ea-4010-edd7-4f4c85bc3a3a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4 Draw a histogram of the sentence length distribution\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the directories containing the datasets\n",
        "train_dir = \"data/train\"\n",
        "val_dir = \"data/val\"\n",
        "test_dir = \"data/test\"\n",
        "\n",
        "# Define a function to get the sentence lengths from a directory of CoNLL-formatted files\n",
        "def get_sentence_lengths(directory):\n",
        "    sentence_lengths = []\n",
        "    for file in os.listdir(directory):\n",
        "        with open(os.path.join(directory, file), 'r') as f:\n",
        "            sentences = f.read().strip().split('\\n\\n')\n",
        "            for sentence in sentences:\n",
        "                words = sentence.split('\\n')\n",
        "                sentence_length = len(words)\n",
        "                sentence_lengths.append(sentence_length)\n",
        "    return sentence_lengths\n",
        "\n",
        "# Get the sentence lengths for each dataset\n",
        "train_lengths = get_sentence_lengths(train_dir)\n",
        "val_lengths = get_sentence_lengths(val_dir)\n",
        "test_lengths = get_sentence_lengths(test_dir)\n",
        "\n",
        "# Plot the sentence length distributions\n",
        "plt.hist(train_lengths, bins=50, alpha=0.5, label=\"Train\")\n",
        "plt.hist(val_lengths, bins=50, alpha=0.5, label=\"Val\")\n",
        "plt.hist(test_lengths, bins=50, alpha=0.5, label=\"Test\")\n",
        "plt.xlabel(\"Sentence length\")\n",
        "plt.ylabel(\"Number of sentences\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "6xcGM1Z3Wcjo",
        "outputId": "ce4ccb81-4895-4d74-a10d-e763c7c78f7c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5 Embedding words using GloVe embedding\n",
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Download the GloVe embeddings\n",
        "url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
        "filename = 'glove.6B.zip'\n",
        "\n",
        "# Download the file using requests\n",
        "response = requests.get(url, stream=True)\n",
        "with open(filename, 'wb') as f:\n",
        "    for chunk in response.iter_content(chunk_size=8192):\n",
        "        f.write(chunk)\n",
        "\n",
        "# Extract the files\n",
        "with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "# Define the path to the glove file\n",
        "glove_file = 'glove.6B.50d.txt'  # 50GloVe\n",
        "\n",
        "# Read the GloVe embed file\n",
        "def read_glove_vectors(glove_file):\n",
        "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "    word_to_vec = {}\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        cols = line.split()\n",
        "        word = cols[0]\n",
        "        vec = np.array(cols[1:], dtype='float32')\n",
        "        word_to_vec[word] = vec\n",
        "    return word_to_vec\n",
        "\n",
        "# Download GloVe word vectors and read them using the modified code\n",
        "embedding_matrix = read_glove_vectors(glove_file)\n",
        "# Get the word vector for a specific word like \"apple\"\n",
        "word_to_vec = read_glove_vectors(glove_file)\n",
        "\n",
        "word = \"bologna\"\n",
        "if word in word_to_vec:\n",
        "    embedding = word_to_vec[word]\n",
        "    print(embedding)\n",
        "else:\n",
        "    print(f\"Word '{word}' not found in the GloVe embeddings.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh3xMvVElrRg",
        "outputId": "33a8fe66-9221-445d-8703-675f558f77e7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.1444    -0.81117   -1.4844    -0.4381     0.074385  -0.61125\n",
            "  0.025821  -0.33074   -1.4416     0.54004    0.12569   -0.62678\n",
            " -0.17099   -0.67438    0.062094  -1.4678    -0.6109     0.25955\n",
            " -0.89278    0.95611   -0.46918   -0.42878   -0.24556    0.76318\n",
            " -0.44466   -0.42965    1.1653     0.44225   -0.65406   -0.76654\n",
            "  1.0743     0.93283   -0.16853    0.12356   -0.30396    0.39219\n",
            "  0.2029     1.8895     0.95429   -0.13466    0.77791   -0.0038449\n",
            "  0.20357   -0.62053    0.045134   1.4153     0.4148    -0.055174\n",
            "  1.0996    -0.29872  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6-1 Compute embeddings for terms in the training split vocabulary V1 (OOV1)\n",
        "\n",
        "# Create a vocabulary from the training data\n",
        "vocab = set()\n",
        "for sentence in train_data:\n",
        "    words = sentence  # Each sentence is already a list of words\n",
        "    vocab.update(words)\n",
        "\n",
        "# Create word to index mapping\n",
        "word_to_index = {word: index for index, word in enumerate(vocab)}\n",
        "\n",
        "# Convert the embedding matrix to a dictionary\n",
        "embedding_dict = {word: embedding_matrix[index] for word, index in word_to_index.items() if word in set(embedding)}\n",
        "\n",
        "# Generate the embedding matrix\n",
        "embedding_dim = 50  # Dimension of GloVe vectors\n",
        "num_words = len(vocab)\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "for index, word in enumerate(word_to_index.keys()):\n",
        "    if word in embedding_dict:\n",
        "        embedding_matrix[index] = embedding_dict[word]\n"
      ],
      "metadata": {
        "id": "39Ae_8_umDlU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6-2 Add embeddings to the vocabulary so that we get vocabulary V2=V1+OOV1\n",
        "\n",
        "# Create a set of all words in V1\n",
        "vocab_v1 = set(vocab)\n",
        "\n",
        "# Add OOV words to V2\n",
        "oov_words = set()\n",
        "for sentence in train_data + val_data + test_data:\n",
        "    words = sentence  # Tokenize the sentence\n",
        "    oov_words.update(word for word in words if word not in vocab_v1)\n",
        "\n",
        "# Create word to index mapping for V2\n",
        "word_to_index_v2 = {word: index for index, word in enumerate(vocab_v1)}\n",
        "\n",
        "# Add OOV words to V2 and assign indices\n",
        "for oov_word in oov_words:\n",
        "    word_to_index_v2[oov_word] = len(word_to_index_v2)\n",
        "\n",
        "# Generate the embedding matrix for V2\n",
        "num_words_v2 = len(word_to_index_v2)\n",
        "embedding_matrix_v2 = np.zeros((num_words_v2, embedding_dim))\n",
        "for word, index in word_to_index_v2.items():\n",
        "    if word in embedding_dict:\n",
        "        embedding_matrix_v2[index] = embedding_dict[word]\n",
        "    else:\n",
        "        # Initialize OOV word embeddings randomly (you can choose any strategy)\n",
        "        embedding_matrix_v2[index] = np.random.uniform(-0.25, 0.25, embedding_dim)\n"
      ],
      "metadata": {
        "id": "K81lzOCOnPkw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6-3 Add embeddings to the vocabulary so that we get vocabulary V2=V1+OOV1\n",
        "\n",
        "# Create a set of all words in the validation set (V2)\n",
        "vocab_v2 = set()\n",
        "for sentence in val_data:\n",
        "    words = sentence  # Tokenize the sentence\n",
        "    vocab_v2.update(words)\n",
        "\n",
        "# Identify OOV2 words (words in vocab_v2 but not in vocab_v1)\n",
        "oov2_words = [word for word in vocab_v2 if word not in vocab_v1]\n",
        "\n",
        "# Create word to index mapping for V2\n",
        "word_to_index_v2 = {word: index for index, word in enumerate(vocab_v1)}\n",
        "\n",
        "# Add OOV2 words to V2 and assign indices\n",
        "for oov2_word in oov2_words:\n",
        "    word_to_index_v2[oov2_word] = len(word_to_index_v2)\n",
        "\n",
        "# Generate the embedding matrix for V2\n",
        "num_words_v2 = len(word_to_index_v2)\n",
        "embedding_matrix_v2 = np.zeros((num_words_v2, embedding_dim))\n",
        "for word, index in word_to_index_v2.items():\n",
        "    if word in embedding_dict:\n",
        "        embedding_matrix_v2[index] = embedding_dict[word]\n",
        "    else:\n",
        "        # Initialize OOV word embeddings randomly (you can choose any strategy)\n",
        "        embedding_matrix_v2[index] = np.random.uniform(-0.25, 0.25, embedding_dim)\n"
      ],
      "metadata": {
        "id": "n9mFqDQ2oQDa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6-4 Add embeddings to the vocabulary so that we get vocabulary V3=V1+OOV1+OOV2\n",
        "\n",
        "# Create a set of all words in the training, validation, and test sets (V3)\n",
        "vocab_v3 = set()\n",
        "for sentence in train_data + val_data + test_data:\n",
        "    words = sentence  # Tokenize the sentence\n",
        "    vocab_v3.update(words)\n",
        "\n",
        "# Identify OOV3 words (words in vocab_v3 but not in vocab_v2)\n",
        "oov3_words = [word for word in vocab_v3 if word not in vocab_v2]\n",
        "\n",
        "# Create word to index mapping for V3\n",
        "word_to_index_v3 = {word: index for index, word in enumerate(word_to_index_v2)}\n",
        "\n",
        "# Create embedding matrix for V3\n",
        "num_words_v3 = len(word_to_index_v3)\n",
        "embedding_matrix_v3 = np.zeros((num_words_v3, embedding_dim))\n",
        "for word, index in word_to_index_v3.items():\n",
        "    if word in embedding_dict:\n",
        "        embedding_matrix_v3[index] = embedding_dict[word]\n",
        "    elif word in oov3_words:\n",
        "        # Initialize OOV word embeddings randomly (you can choose any strategy)\n",
        "        embedding_matrix_v3[index] = np.random.uniform(-0.25, 0.25, embedding_dim)\n"
      ],
      "metadata": {
        "id": "h6Z17lUbo0-2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6-5 Computing the embedding of the term OOV3 for the test split\n",
        "\n",
        "# Create a set of all words in the test set (V3)\n",
        "vocab_test = set()\n",
        "for sentence in test_data:\n",
        "    words = sentence # Tokenize the sentence\n",
        "    vocab_test.update(words)\n",
        "\n",
        "# Identify OOV3 words (words in vocab_test but not in vocab_v3)\n",
        "oov3_words_test = [word for word in vocab_test if word not in vocab_v3]\n",
        "\n",
        "# Create word to index mapping for V3\n",
        "word_to_index_test = {word: index for index, word in enumerate(word_to_index_v3)}\n",
        "\n",
        "# Create embedding matrix for testing OOV3 words\n",
        "num_words_test = len(word_to_index_test)\n",
        "embedding_matrix_test = np.zeros((num_words_test, embedding_dim))\n",
        "for word, index in word_to_index_test.items():\n",
        "    if word in embedding_dict:\n",
        "        embedding_matrix_test[index] = embedding_dict[word]\n",
        "    elif word in oov3_words_test:\n",
        "        # Initialize OOV word embeddings randomly (you can choose any strategy)\n",
        "        embedding_matrix_test[index] = np.random.uniform(-0.25, 0.25, embedding_dim)\n"
      ],
      "metadata": {
        "id": "6qiZYcNCo7P1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6-6 Add embeddings to the vocabulary so that we get vocabulary V4=V1+OOV1+OOV2+OOV3\n",
        "\n",
        "# Create a set of OOV1 words (words in V2 but not in V1)\n",
        "oov1_words = [word for word in vocab_v2 if word not in vocab_v1]\n",
        "\n",
        "# Create a set of OOV2 words (words in V3 but not in V2)\n",
        "oov2_words = [word for word in vocab_v3 if word not in vocab_v2]\n",
        "\n",
        "# Create a set of OOV3 words (words in test set but not in V3)\n",
        "oov3_words = [word for word in vocab_test if word not in vocab_v3]\n",
        "\n",
        "# Create a set of all words in V1, OOV1, OOV2, and OOV3\n",
        "vocab_v4 = set(vocab_v1).union(set(oov1_words), set(oov2_words), set(oov3_words))\n",
        "\n",
        "# Create word to index mapping for V4\n",
        "word_to_index_v4 = {word: index for index, word in enumerate(word_to_index_v3)}\n",
        "\n",
        "# Add OOV4 words to V4 and assign indices\n",
        "for oov4_word in vocab_v4:\n",
        "    if oov4_word not in word_to_index_v4:\n",
        "        word_to_index_v4[oov4_word] = len(word_to_index_v4)\n",
        "\n",
        "# Generate the embedding matrix for V4\n",
        "num_words_v4 = len(word_to_index_v4)\n",
        "embedding_matrix_v4 = np.zeros((num_words_v4, embedding_dim))\n",
        "for word, index in word_to_index_v4.items():\n",
        "    if word in embedding_dict:\n",
        "        embedding_matrix_v4[index] = embedding_dict[word]\n",
        "    else:\n",
        "        # Initialize OOV word embeddings randomly (you can choose any strategy)\n",
        "        embedding_matrix_v4[index] = np.random.uniform(-0.25, 0.25, embedding_dim)\n"
      ],
      "metadata": {
        "id": "9so8yTmOpFt8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7 Prepare the model\n",
        "finally train the mode\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Define hyperparameters\n",
        "hidden_size = 100\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "\n",
        "# Convert embedding_matrix to PyTorch tensor\n",
        "embedding_matrix_tensor = torch.tensor(embedding_matrix, dtype=torch.float)\n",
        "\n",
        "\n",
        "# Create a label to index mapping\n",
        "label_index_mapping = {}\n",
        "for idx, label in enumerate(sorted(set(train_df['POS']))):\n",
        "    label_index_mapping[label] = idx\n",
        "\n",
        "# Convert words in text data to corresponding indices using word_to_index_v4\n",
        "train_data_indices = [[word_to_index_v4[word] for word in sentence.split()] for sentence in train_df['Word']]\n",
        "train_labels = [label_index_mapping[label] for label in train_df['POS']]\n",
        "\n",
        "# Find the maximum sentence length in train_data_indices\n",
        "max_sentence_length = max(len(sentence) for sentence in train_data_indices)\n",
        "\n",
        "# Pad sentences to the maximum length\n",
        "padded_train_data_indices = [sentence + [0] * (max_sentence_length - len(sentence)) for sentence in train_data_indices]\n",
        "\n",
        "# Convert to PyTorch tensor\n",
        "train_data_indices_tensor = torch.tensor(padded_train_data_indices)\n",
        "\n",
        "# Create DataLoader for training data\n",
        "train_dataset = TensorDataset(train_data_indices_tensor, torch.tensor(train_labels))\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "# Check missing labels in validation data\n",
        "missing_labels = set(val_df['POS']) - set(label_index_mapping.keys())\n",
        "\n",
        "# Add missing labels to label_index_mapping with appropriate indices\n",
        "for missing_label in missing_labels:\n",
        "    label_index_mapping[missing_label] = len(label_index_mapping)\n",
        "\n",
        "# Convert words in validation data to corresponding indices using word_to_index_v4\n",
        "val_data_indices = [[word_to_index_v4[word] for word in sentence.split()] for sentence in val_df['Word']]\n",
        "val_labels = [label_index_mapping[label] for label in val_df['POS']]\n",
        "\n",
        "# Find the maximum sentence length in validation data_indices\n",
        "max_val_sentence_length = max(len(sentence) for sentence in val_data_indices)\n",
        "\n",
        "# Pad validation sentences to the maximum length\n",
        "padded_val_data_indices = [sentence + [0] * (max_val_sentence_length - len(sentence)) for sentence in val_data_indices]\n",
        "\n",
        "# Convert to PyTorch tensor\n",
        "val_data_indices_tensor = torch.tensor(padded_val_data_indices)\n",
        "\n",
        "# Create DataLoader for validation data\n",
        "val_dataset = TensorDataset(val_data_indices_tensor, torch.tensor(val_labels))\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)  # No need to shuffle for validation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#7 Create a baseline model using a simple neural architecture\n",
        "# Baseline: Two-layer architecture: a bidirectional LSTM layer and a dense/fully connected layer on top.\n",
        "#Architecture: Experiment with GRUs instead of LSTMs, add extra LSTM layers, and add extra dense layers.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, embedding_matrix_v4, hidden_size, num_classes):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix_v4, padding_idx=0, freeze=True)\n",
        "        self.gru = nn.GRU(input_size=embedding_matrix_v4.shape[1], hidden_size=hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, _ = self.gru(x)\n",
        "        output = self.fc1(output[:, -1, :])\n",
        "        output = self.relu(output)\n",
        "        output = self.fc2(output)\n",
        "        return output\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "embedding_matrix_v4_tensor = torch.tensor(embedding_matrix_v4, dtype=torch.float).to(device)\n",
        "model_GRU = GRUModel(embedding_matrix_v4_tensor, hidden_size=100, num_classes=10).to(device)\n",
        "\n",
        "print(model_GRU)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X9M5qXpuBTk",
        "outputId": "b72f2a28-6413-44a2-ef23-422c1f1d28cd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GRUModel(\n",
            "  (embedding): Embedding(12003, 50, padding_idx=0)\n",
            "  (gru): GRU(50, 100, batch_first=True, bidirectional=True)\n",
            "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8 Based on the extension and improvement of the baseline model, by adding layers and parameters, different model configurations can be tried to achieve better performance.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class ModifiedModel(nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_classes):\n",
        "        super(ModifiedModel, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix_v4))\n",
        "        self.gru = nn.GRU(input_size=embedding_matrix_v4.shape[1], hidden_size=hidden_size, num_layers=2, batch_first=True, bidirectional=True)\n",
        "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, _ = self.gru(x)\n",
        "        output = output[:, -1, :]\n",
        "        output = self.fc1(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.fc2(output)\n",
        "        return output\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_modified = ModifiedModel(embedding_matrix_v4, hidden_size=100, num_classes=10).to(device)\n",
        "\n",
        "print(model_modified)\n",
        "\n"
      ],
      "metadata": {
        "id": "T-gd0F0gNmc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15234404-7292-4638-82d3-0e748a9a72b7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ModifiedModel(\n",
            "  (embedding): Embedding(12003, 50)\n",
            "  (gru): GRU(50, 100, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#9 Define hyperparameters\n",
        "hidden_size = 100\n",
        "num_classes = len(label_index_mapping)\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "\n",
        "# Create an instance of the ModifiedModel\n",
        "model = ModifiedModel(embedding_matrix_v4, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Variables to track the best model and its performance\n",
        "best_val_accuracy = 0.0\n",
        "best_model_weights = None\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for batch_inputs, batch_labels in train_loader:\n",
        "        batch_inputs = batch_inputs.to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(batch_inputs)\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for val_inputs, val_labels in val_loader:\n",
        "            val_inputs = val_inputs.to(device)\n",
        "            val_labels = val_labels.to(device)\n",
        "\n",
        "            val_outputs = model(val_inputs)\n",
        "            _, val_predicted = torch.max(val_outputs, 1)\n",
        "\n",
        "            val_total += val_labels.size(0)\n",
        "            val_correct += (val_predicted == val_labels).sum().item()\n",
        "\n",
        "    val_accuracy = val_correct / val_total\n",
        "\n",
        "    # Check if current model has better validation accuracy than the best one so far\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        best_model_weights = model.state_dict().copy()  # Save the best model weights\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# Save the best model weights\n",
        "torch.save(best_model_weights, \"best_model_weights.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGhhdOyOZ3O1",
        "outputId": "ec7ba275-7df2-4e52-a3cf-2ff7f00946e9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.8330, Validation Accuracy: 0.5703\n",
            "Epoch [2/10], Loss: 1.3032, Validation Accuracy: 0.6200\n",
            "Epoch [3/10], Loss: 1.1292, Validation Accuracy: 0.6457\n",
            "Epoch [4/10], Loss: 0.9961, Validation Accuracy: 0.6937\n",
            "Epoch [5/10], Loss: 0.8751, Validation Accuracy: 0.7261\n",
            "Epoch [6/10], Loss: 0.7644, Validation Accuracy: 0.7454\n",
            "Epoch [7/10], Loss: 0.6671, Validation Accuracy: 0.7570\n",
            "Epoch [8/10], Loss: 0.5891, Validation Accuracy: 0.7706\n",
            "Epoch [9/10], Loss: 0.5232, Validation Accuracy: 0.7856\n",
            "Epoch [10/10], Loss: 0.4699, Validation Accuracy: 0.7934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#10 Create two best models\n",
        "class Model1(nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_classes):\n",
        "        super(Model1, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix_v4))\n",
        "        self.gru = nn.GRU(input_size=embedding_matrix_v4.shape[1], hidden_size=hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, _ = self.gru(x)\n",
        "        output = output[:, -1, :]\n",
        "        output = self.fc1(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.fc2(output)\n",
        "        return output\n",
        "\n",
        "model1 = Model1(embedding_matrix_v4, hidden_size, num_classes).to(device)\n",
        "\n",
        "\n",
        "class Model2(nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_classes):\n",
        "        super(Model2, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix_v4))\n",
        "        self.lstm = nn.GRU(input_size=embedding_matrix_v4.shape[1], hidden_size=hidden_size, num_layers=2, batch_first=True, bidirectional=True)\n",
        "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, _ = self.lstm(x)\n",
        "        output = output[:, -1, :]\n",
        "        output = self.fc1(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.fc2(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "model2 = Model2(embedding_matrix_v4, hidden_size, num_classes).to(device)\n",
        "\n",
        "class Model3(nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_classes):\n",
        "        super(Model3, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix_v4))\n",
        "        self.lstm = nn.LSTM(input_size=embedding_matrix_v4.shape[1], hidden_size=hidden_size, num_layers=2, batch_first=True, bidirectional=True)\n",
        "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, _ = self.lstm(x)\n",
        "        output = output[:, -1, :]\n",
        "        output = self.fc1(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.fc2(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "model3 = Model3(embedding_matrix_v4, hidden_size, num_classes).to(device)\n",
        "\n",
        "print(model1,model2,model3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0bJ88UVhof5",
        "outputId": "386f5f4d-ee8b-477b-af88-c48a174d8ac2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model1(\n",
            "  (embedding): Embedding(12003, 50)\n",
            "  (gru): GRU(50, 100, batch_first=True, bidirectional=True)\n",
            "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=100, out_features=45, bias=True)\n",
            ") Model2(\n",
            "  (embedding): Embedding(12003, 50)\n",
            "  (lstm): GRU(50, 100, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=100, out_features=45, bias=True)\n",
            ") Model3(\n",
            "  (embedding): Embedding(12003, 50)\n",
            "  (lstm): LSTM(50, 100, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=100, out_features=45, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#11.three different models are trained, namely Model1 and Model2, using a similar training loop structure.\n",
        "#Each model has its own loss function, optimizer and training/validation loop.\n",
        "\n",
        "# Define loss function and optimizer for Model1\n",
        "criterion1 = nn.CrossEntropyLoss()\n",
        "optimizer1 = optim.Adam(model1.parameters(), lr=learning_rate)\n",
        "\n",
        "# Variables to track the best model and its performance for Model1\n",
        "best_val_accuracy1 = 0.0\n",
        "best_model_weights1 = None\n",
        "\n",
        "# Training loop for Model1\n",
        "for epoch in range(num_epochs):\n",
        "    model1.train()\n",
        "    total_loss = 0.0\n",
        "    for batch_inputs, batch_labels in train_loader:\n",
        "        batch_inputs = batch_inputs.to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "\n",
        "        optimizer1.zero_grad()\n",
        "\n",
        "        outputs = model1(batch_inputs)\n",
        "        loss = criterion1(outputs, batch_labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer1.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation for Model1\n",
        "    model1.eval()\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for val_inputs, val_labels in val_loader:\n",
        "            val_inputs = val_inputs.to(device)\n",
        "            val_labels = val_labels.to(device)\n",
        "\n",
        "            val_outputs = model1(val_inputs)\n",
        "            _, val_predicted = torch.max(val_outputs, 1)\n",
        "\n",
        "            val_total += val_labels.size(0)\n",
        "            val_correct += (val_predicted == val_labels).sum().item()\n",
        "\n",
        "    val_accuracy = val_correct / val_total\n",
        "\n",
        "    # Check if current model has better validation accuracy than the best one so far for Model1\n",
        "    if val_accuracy > best_val_accuracy1:\n",
        "        best_val_accuracy1 = val_accuracy\n",
        "        best_model_weights1 = model1.state_dict().copy()  # Save the best model weights for Model1\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Model1, Loss: {avg_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# Save the best model weights for Model1\n",
        "torch.save(best_model_weights1, \"best_model_weights_model1.pth\")\n",
        "\n",
        "\n",
        "\n",
        "# Similar training loop and saving for Model2\n",
        "# Define loss function and optimizer for Model2\n",
        "criterion2 = nn.CrossEntropyLoss()\n",
        "optimizer2 = optim.Adam(model2.parameters(), lr=learning_rate)\n",
        "\n",
        "# Variables to track the best model and its performance for Model2\n",
        "best_val_accuracy2 = 0.0\n",
        "best_model_weights2 = None\n",
        "\n",
        "# Training loop for Model2\n",
        "for epoch in range(num_epochs):\n",
        "    model2.train()\n",
        "    total_loss = 0.0\n",
        "    for batch_inputs, batch_labels in train_loader:\n",
        "        batch_inputs = batch_inputs.to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "\n",
        "        optimizer2.zero_grad()\n",
        "\n",
        "        outputs = model2(batch_inputs)\n",
        "        loss = criterion2(outputs, batch_labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer2.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation for Model2\n",
        "    model2.eval()\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for val_inputs, val_labels in val_loader:\n",
        "            val_inputs = val_inputs.to(device)\n",
        "            val_labels = val_labels.to(device)\n",
        "\n",
        "            val_outputs = model2(val_inputs)\n",
        "            _, val_predicted = torch.max(val_outputs, 1)\n",
        "\n",
        "            val_total += val_labels.size(0)\n",
        "            val_correct += (val_predicted == val_labels).sum().item()\n",
        "\n",
        "    val_accuracy = val_correct / val_total\n",
        "\n",
        "    # Check if current model has better validation accuracy than the best one so far for Model2\n",
        "    if val_accuracy > best_val_accuracy2:\n",
        "        best_val_accuracy2 = val_accuracy\n",
        "        best_model_weights2 = model2.state_dict().copy()  # Save the best model weights for Model2\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Model2, Loss: {avg_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# Save the best model weights for Model2\n",
        "torch.save(best_model_weights2, \"best_model_weights_model2.pth\")\n",
        "\n",
        "\n",
        "\n",
        "# Define loss function and optimizer for Model3\n",
        "criterion3 = nn.CrossEntropyLoss()\n",
        "optimizer3 = optim.Adam(model3.parameters(), lr=learning_rate)\n",
        "\n",
        "# Variables to track the best model and its performance for Model3\n",
        "best_val_accuracy3 = 0.0\n",
        "best_model_weights3 = None\n",
        "\n",
        "# Training loop for Model3\n",
        "for epoch in range(num_epochs):\n",
        "    model3.train()\n",
        "    total_loss = 0.0\n",
        "    for batch_inputs, batch_labels in train_loader:\n",
        "        batch_inputs = batch_inputs.to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "\n",
        "        optimizer3.zero_grad()\n",
        "\n",
        "        outputs = model3(batch_inputs)\n",
        "        loss = criterion3(outputs, batch_labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer3.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation for Model3\n",
        "    model3.eval()\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for val_inputs, val_labels in val_loader:\n",
        "            val_inputs = val_inputs.to(device)\n",
        "            val_labels = val_labels.to(device)\n",
        "\n",
        "            val_outputs = model3(val_inputs)\n",
        "            _, val_predicted = torch.max(val_outputs, 1)\n",
        "\n",
        "            val_total += val_labels.size(0)\n",
        "            val_correct += (val_predicted == val_labels).sum().item()\n",
        "\n",
        "    val_accuracy = val_correct / val_total\n",
        "\n",
        "    # Check if current model has better validation accuracy than the best one so far for Model3\n",
        "    if val_accuracy > best_val_accuracy3:\n",
        "        best_val_accuracy3 = val_accuracy\n",
        "        best_model_weights3 = model3.state_dict().copy()  # Save the best model weights for Model3\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Model3, Loss: {avg_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# Save the best model weights for Model3\n",
        "torch.save(best_model_weights3, \"best_model_weights_model3.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t7GFct8hZlk",
        "outputId": "858917e9-792f-47a6-9797-7f74f9189aa4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] - Model1, Loss: 0.4484, Validation Accuracy: 0.7924\n",
            "Epoch [2/10] - Model1, Loss: 0.4288, Validation Accuracy: 0.7949\n",
            "Epoch [3/10] - Model1, Loss: 0.4142, Validation Accuracy: 0.8014\n",
            "Epoch [4/10] - Model1, Loss: 0.3986, Validation Accuracy: 0.8042\n",
            "Epoch [5/10] - Model1, Loss: 0.3842, Validation Accuracy: 0.8040\n",
            "Epoch [6/10] - Model1, Loss: 0.3701, Validation Accuracy: 0.8040\n",
            "Epoch [7/10] - Model1, Loss: 0.3554, Validation Accuracy: 0.8042\n",
            "Epoch [8/10] - Model1, Loss: 0.3436, Validation Accuracy: 0.8067\n",
            "Epoch [9/10] - Model1, Loss: 0.3309, Validation Accuracy: 0.8054\n",
            "Epoch [10/10] - Model1, Loss: 0.3212, Validation Accuracy: 0.8069\n",
            "Epoch [1/10] - Model2, Loss: 0.1992, Validation Accuracy: 0.8271\n",
            "Epoch [2/10] - Model2, Loss: 0.1890, Validation Accuracy: 0.8269\n",
            "Epoch [3/10] - Model2, Loss: 0.1838, Validation Accuracy: 0.8300\n",
            "Epoch [4/10] - Model2, Loss: 0.1805, Validation Accuracy: 0.8284\n",
            "Epoch [5/10] - Model2, Loss: 0.1766, Validation Accuracy: 0.8265\n",
            "Epoch [6/10] - Model2, Loss: 0.1733, Validation Accuracy: 0.8304\n",
            "Epoch [7/10] - Model2, Loss: 0.1728, Validation Accuracy: 0.8280\n",
            "Epoch [8/10] - Model2, Loss: 0.1698, Validation Accuracy: 0.8286\n",
            "Epoch [9/10] - Model2, Loss: 0.1682, Validation Accuracy: 0.8335\n",
            "Epoch [10/10] - Model2, Loss: 0.1656, Validation Accuracy: 0.8266\n",
            "Epoch [1/10] - Model3, Loss: 2.0074, Validation Accuracy: 0.5206\n",
            "Epoch [2/10] - Model3, Loss: 1.4058, Validation Accuracy: 0.5919\n",
            "Epoch [3/10] - Model3, Loss: 1.2144, Validation Accuracy: 0.6304\n",
            "Epoch [4/10] - Model3, Loss: 1.0971, Validation Accuracy: 0.6627\n",
            "Epoch [5/10] - Model3, Loss: 0.9919, Validation Accuracy: 0.6923\n",
            "Epoch [6/10] - Model3, Loss: 0.8940, Validation Accuracy: 0.7126\n",
            "Epoch [7/10] - Model3, Loss: 0.8064, Validation Accuracy: 0.7333\n",
            "Epoch [8/10] - Model3, Loss: 0.7250, Validation Accuracy: 0.7523\n",
            "Epoch [9/10] - Model3, Loss: 0.6553, Validation Accuracy: 0.7631\n",
            "Epoch [10/10] - Model3, Loss: 0.5915, Validation Accuracy: 0.7773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#12 Prepare test data\n",
        "#Convert words in test data to corresponding indices using word_to_index_v4\n",
        "test_data_indices = [[word_to_index_v4[word] for word in sentence.split()] for sentence in test_df['Word']]\n",
        "test_labels = [label_index_mapping[label] for label in test_df['POS']]\n",
        "\n",
        "# Find the maximum sentence length in test data_indices\n",
        "max_test_sentence_length = max(len(sentence) for sentence in test_data_indices)\n",
        "\n",
        "# Pad test sentences to the maximum length\n",
        "padded_test_data_indices = [sentence + [0] * (max_test_sentence_length - len(sentence)) for sentence in test_data_indices]\n",
        "\n",
        "# Convert to PyTorch tensor\n",
        "test_data_indices_tensor = torch.tensor(padded_test_data_indices)\n",
        "\n",
        "# Create DataLoader for test data\n",
        "test_dataset = TensorDataset(test_data_indices_tensor, torch.tensor(test_labels))\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)  # No need to shuffle for test\n"
      ],
      "metadata": {
        "id": "90bGY6QKhzwj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13.Accuracy and F1-Macro scores\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    f1_macro = f1_score(all_labels, all_predictions, average='macro')\n",
        "\n",
        "    return accuracy, f1_macro\n",
        "\n",
        "# Load the best model weights for Model1 and Model2,model3\n",
        "model1.load_state_dict(torch.load(\"best_model_weights_model1.pth\"))\n",
        "model2.load_state_dict(torch.load(\"best_model_weights_model2.pth\"))\n",
        "model3.load_state_dict(torch.load(\"best_model_weights_model3.pth\"))\n",
        "\n",
        "# Create DataLoader for test data\n",
        "test_data_indices = [[word_to_index_v4[word] for word in sentence.split()] for sentence in test_df['Word']]\n",
        "padded_test_data_indices = [sentence + [0] * (max_sentence_length - len(sentence)) for sentence in test_data_indices]\n",
        "test_data_indices_tensor = torch.tensor(padded_test_data_indices)\n",
        "test_labels = [label_index_mapping[label] for label in test_df['POS']]\n",
        "test_dataset = TensorDataset(test_data_indices_tensor, torch.tensor(test_labels))\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Evaluate Model1\n",
        "accuracy_model1, f1_macro_model1 = evaluate_model(model1, test_loader)\n",
        "print(f\"Model1 - Test Accuracy: {accuracy_model1:.4f}, Test F1-Macro: {f1_macro_model1:.4f}\")\n",
        "\n",
        "# Evaluate Model2\n",
        "accuracy_model2, f1_macro_model2 = evaluate_model(model2, test_loader)\n",
        "print(f\"Model2 - Test Accuracy: {accuracy_model2:.4f}, Test F1-Macro: {f1_macro_model2:.4f}\")\n",
        "\n",
        "# Evaluate Model3\n",
        "accuracy_model3, f1_macro_model3 = evaluate_model(model3, test_loader)\n",
        "print(f\"Model3 - Test Accuracy: {accuracy_model2:.4f}, Test F1-Macro: {f1_macro_model3:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdTuwfuLbwaq",
        "outputId": "d35270b7-c59d-41b4-f5b5-ef2aceb8f3f5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model1 - Test Accuracy: 0.8144, Test F1-Macro: 0.7823\n",
            "Model2 - Test Accuracy: 0.8313, Test F1-Macro: 0.7625\n",
            "Model3 - Test Accuracy: 0.8313, Test F1-Macro: 0.7575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K3xmHEOpnTB9"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}